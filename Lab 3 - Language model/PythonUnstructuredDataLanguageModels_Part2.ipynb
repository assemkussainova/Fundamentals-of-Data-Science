{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vtBmextYoqYh"
   },
   "source": [
    "# Part 2\n",
    "In the first part, we have seen how to compute joint probability of a sentence using the independence assumption.\n",
    "However, this assumption is too weak as words do depend on each other. In the second part, we would like to introduce a better approach using Markov chain."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ufdA7IoKQQ7C"
   },
   "source": [
    "#### Markov chain\n",
    "\n",
    "Markov chain is based on the following assumption: *given the present, the future does not depend on the past*.\n",
    "\n",
    "##### Zeroth order Markov chain\n",
    "The simplest form of Markov chain is so called zeroth order Markov chain where words are completely independent from each other:\n",
    "\n",
    "$p(w_1\\ w_2\\ \\dots\\ w_{|T|}) \\approx p(w_1)\\ p(w_2)\\ p(w_3)\\ \\dots \\ p(w_{|T|}) = \\prod^{|T|}_{i=1}p(w_i)$\n",
    "\n",
    "Recall that this is similar to the independence assumption covered in the first part.\n",
    "In literature, this probabilistic model is also known as unigram language model.\n",
    "\n",
    "##### First order Markov chain:\n",
    "In the first order Markov chain, a probability of a word is conditioned only on the preceeding word:\n",
    "\n",
    "$p(w_1\\ w_2\\ \\dots\\ w_{|T|}) \\approx p(w_1)\\ p(w_2|w_1)\\ p(w_2|w_3)\\ \\dots \\ p(w_{|T|}|w_{|T|-1}) = p(w_1)\\prod^{|T|}_{i=2}p(w_i|w_{i-1})$\n",
    "\n",
    "where conditional probabilities are estimated as:\n",
    "\n",
    "$p(w_i|w_{i-1})=\\frac{count(w_{i-1}\\ w_{i})}{count(w_{i-1})}$\n",
    "\n",
    "In literature, this probabilistic model is called bigram (or 2-gram) language model.\n",
    "\n",
    "Similarly, in the N-th order Markov chain, a probability of a word is conditioned only on the preceeding N words.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Y9ZTGse1-wh4"
   },
   "source": [
    "For each of the following tasks we will continue working with PTB dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZuvRC5V3Uxxm"
   },
   "source": [
    "### Task 1: Computing probability of a sentence (first order Markov chain)\n",
    "Write a function called **compute_prob1** which takes a sentence as input (and maybe some additional arguments) and returns its probability estimated using the first order Markov chain. \n",
    "\n",
    "Your function should first append **\\<bos>** and **\\<eos>** symbols to the input sentence  and replace all words that are not present in the dictionary with **\\<unk>** symbol. \n",
    "\n",
    "If the original sentence was \"my name is madina\", then \"madina\" is obviously not in the dictionary (see the description of the PTB). The probability of such sentence can be computed as:\n",
    "  p(\"my name is madina\") = p(\"my\" | \"\\<bos>\") * p(\"name\" | \"my\") * p(\"is\" | \"name\") * p(\"\\<unk>\" | \"is\") * p(\"\\<eos>\" | \"\\<unk>\")\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vSgACpZwjzI6"
   },
   "source": [
    "If you completed the task correctly then your function should compute:\n",
    "\n",
    "p(\"my name is madina\") = 8.512130344833542e-10\n",
    "\n",
    "p(\"hello how are you\") = 6.89010961921847e-13\n",
    "\n",
    "p(\"this is an estimate\") = 4.418442586905126e-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "text = open('ptb.train.txt', encoding='utf8').read()\n",
    "data = text.split('\\n')\n",
    "data = [sent for sent in data if sent != '']\n",
    "for i in range(len(data)):\n",
    "    data[i] = ''.join(('<bos>', data[i],'<eos>'))\n",
    "    \n",
    "d = []\n",
    "for string in data:\n",
    "    s = string.split()\n",
    "    for e in s:\n",
    "        d.append(e)\n",
    "\n",
    "dictionary = dict()\n",
    "for w in d:\n",
    "    if w in dictionary:\n",
    "        dictionary[w] += 1\n",
    "    else:\n",
    "        dictionary[w] = 1\n",
    "\n",
    "s = sum(dictionary.values())\n",
    "dictionary_prob = dict()\n",
    "for i in dictionary:\n",
    "    dictionary_prob[i] = dictionary[i]/s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my name is madina\n",
      "8.512130344833542e-10 \n",
      "\n",
      "hello how are you\n",
      "6.89010961921847e-13 \n",
      "\n",
      "this is an estimate\n",
      "4.418442586905126e-10 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "def compute_prob1(s, d, dct):\n",
    "    s = ''.join(('<bos>', ' ', s, ' ', '<eos>'))\n",
    "    s = s.split(' ')\n",
    "    for i in range(len(s)):\n",
    "        if s[i] not in d:\n",
    "            s[i] = \"<unk>\"\n",
    "            \n",
    "    p = 1 \n",
    "    for i in range(len(s)-1):\n",
    "        count = 0\n",
    "        for j in range(len(d)-1):\n",
    "            if (s[i] == d[j]) & (s[i+1] == d[j+1]):\n",
    "                count += 1\n",
    "        if count > 0:\n",
    "            p *= count/dct[s[i]]                \n",
    "    return p\n",
    "\n",
    "for i in range(3):\n",
    "    sent = input()\n",
    "    print(compute_prob1(sent, d, dictionary), '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "B9RiOUyde2te"
   },
   "source": [
    "### Task 2: Predicting the most likely next words (Autocomplete)\n",
    "In this task, you will implement autocomeplete function which is similar to the message completion service in mobile phones.\n",
    "\n",
    "Write a function **autofill** which takes a word and integer k as input (and maybe some additional arguments) and returns k most probable words to follow it according to the estimates computed by first order Markov chain.\n",
    "\n",
    "If you completed the task correctly, your function should return that the 5 most probable words to follow \"san\" are \\['francisco', '\\<unk>', 'jose', 'diego', 'antonio'\\]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "k7wRCUivfzHO"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "san\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['francisco', '<unk>', 'jose', 'diego', 'antonio']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def autofill(n, w, dt):\n",
    "    nex = dict()\n",
    "    for i in range(len(dt)-1):\n",
    "        if dt[i] == w:\n",
    "            if dt[i+1] in nex:\n",
    "                nex[dt[i+1]] += 1\n",
    "            else:\n",
    "                nex[dt[i+1]] = 1\n",
    "    \n",
    "    sortedAns = sorted(nex, key=nex.get, reverse = True)\n",
    "    \n",
    "    if len(sortedAns) >= int(n):\n",
    "        return sortedAns[0:int(n)]\n",
    "    else:\n",
    "        return \"Try another number\"\n",
    "\n",
    "num = input()\n",
    "word = input()\n",
    "autofill(num, word, d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "v7NgIjVzU6Id"
   },
   "source": [
    "### Task 3: Generate a text (zeroth order Markov chain)\n",
    "Write a function **generate_text0** which takes as an input integer k (and maybe some additional arguments) and generates k sentences sampled from the probability distribution estimated by the zeroth order Markov chain. \n",
    "\n",
    "The length of each sentence should be at least 3 words, including \\<bos> and \\<eos>. For example \"\\<bos> is \\<eos>\".\n",
    "\n",
    "\\<bos> and \\<eos> must not appear in the middle of a sentence.\n",
    "\n",
    "Hint: you can use random.choices() for sampling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hrrIUgyrfZV9"
   },
   "source": [
    "If you completed the task correctly, then for k = 2 your output would look like this (but with different sentences):\n",
    "\n",
    "['\\<bos> fees property the year 's drop world died or \\<unk> j. trust the which for meanwhile action economic criminal germany \\<unk> by with white \\<eos>',\n",
    "\n",
    " '\\<bos> koch to a N laws \\<eos>']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UeG81MYXfy1d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter number of sentences: \n",
      "10\n",
      "<bos> or he N <unk> <eos>\n",
      "<bos> consistently improving case <eos>\n",
      "<bos> fairly remarks tv <eos>\n",
      "<bos> dec. reflecting bond this the <unk> ' <eos>\n",
      "<bos> this and some star years leading <eos>\n",
      "<bos> half inc. partnership they <eos>\n",
      "<bos> from since jenrette as australia if give <eos>\n",
      "<bos> the asking 1980s hit for raised but over <eos>\n",
      "<bos> donald agency anheuser after volume of instruction company <eos>\n",
      "<bos> program too <unk> $ <eos>\n"
     ]
    }
   ],
   "source": [
    "def generate_text0(n, dat): \n",
    "   \n",
    "    for i in range(int(n)):\n",
    "        choose = np.random.choice(dat)\n",
    "        if choose != '<bos>' and choose != '<eos>':\n",
    "            first_word = choose\n",
    "        sentence = [first_word]\n",
    "        n_words = random.randint(1, 7)\n",
    "    \n",
    "        for i in range(n_words):\n",
    "            w = np.random.choice(dat)\n",
    "            if w != '<bos>' and w != '<eos>':\n",
    "                sentence.append(w)\n",
    "        sentence = ' '.join(sentence)\n",
    "        print(' '.join(('<bos>', sentence,'<eos>')))\n",
    "    \n",
    "print(\"Enter number of sentences: \")\n",
    "k = input()\n",
    "generate_text0(k, d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YP-PdI64VMom"
   },
   "source": [
    "### Task 4: Generate a text (first order Markov chain)\n",
    "Write a function **generate_text1** which takes as an input integer k (and maybe some additional arguments) and generates k sentences sampled from the probability distribution estimated using the first order Markov chain.\n",
    "\n",
    "The length of each sentence should be at least 3 words, including \\<bos> and \\<eos>. For example \"\\<bos> is \\<eos>\".\n",
    "\n",
    "\\<bos> and \\<eos> must not appear in the middle of a sentence.\n",
    "\n",
    "Hint: you can use random.choices() for sampling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rGsdiKKSf2rT"
   },
   "source": [
    "If you completed the task correctly, then for k = 2 your output would look like this (but with different sentences):\n",
    "\n",
    "['\\<bos> what happened at st. louis assembly business \\<eos>',\n",
    "\n",
    " '\\<bos> integrated combines some people familiar with forecasts \\<eos>',"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "z7naHG2waW0l"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter number of sentences: \n",
      "2\n",
      "legal\n",
      "<unk>\n",
      "<bos> conservative legal <unk> <eos>\n",
      "until\n",
      "he\n",
      "<unk>\n",
      "<unk>\n",
      "messrs.\n",
      "watson\n",
      "<bos> <unk> until he <unk> <unk> messrs. watson <eos>\n"
     ]
    }
   ],
   "source": [
    "def generate_text1(n, dat): \n",
    "    \n",
    "    def create_dict(a):\n",
    "        for i in range(len(a) - 1):\n",
    "            yield (a[i], a[i + 1])\n",
    "    chain_dict = create_dict(dat)\n",
    "\n",
    "    word_dict = {}\n",
    "    for present, future in chain_dict:\n",
    "        if present in word_dict.keys():\n",
    "            word_dict[present].append(future)\n",
    "        else:\n",
    "            word_dict[present] = [future]\n",
    "   \n",
    "    for i in range(int(n)):\n",
    "        choose = np.random.choice(dat)\n",
    "        if choose != '<bos>' and choose != '<eos>':\n",
    "            first_word = choose\n",
    "        sentence = [first_word]\n",
    "        n_words = random.randint(1, 7)\n",
    "    \n",
    "        for i in range(n_words):\n",
    "            w = np.random.choice(word_dict[sentence[-1]])\n",
    "            if w != '<bos>' and w != '<eos>':\n",
    "                sentence.append(w)\n",
    "        sentence = ' '.join(sentence)\n",
    "        print(' '.join(('<bos>', sentence,'<eos>')))\n",
    "    \n",
    "print(\"Enter number of sentences: \")\n",
    "k = input()\n",
    "generate_text1(k, d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dict(d):\n",
    "    for i in range(len(d) - 2):\n",
    "        yield (d[i], d[i + 1], d[i + 2])\n",
    "chain_dict = create_dict(d)\n",
    "\n",
    "word_dict = {}\n",
    "\n",
    "for present, present2, future in chain_dict:\n",
    "    dkey = [present, present2]\n",
    "    if tuple(dkey) in word_dict.keys():\n",
    "        word_dict[tuple(dkey)].append(future)\n",
    "    else:\n",
    "        word_dict[tuple(dkey)] = [future]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text2(n, dat): \n",
    "    \n",
    "    def create_dict(d):\n",
    "        for i in range(len(d) - 2):\n",
    "            yield (d[i], d[i + 1], d[i + 2])\n",
    "    chain_dict = create_dict(d)\n",
    "\n",
    "    word_dict = {}\n",
    "\n",
    "    for present, present2, future in chain_dict:\n",
    "        dkey = [present, present2]\n",
    "        if tuple(dkey) in word_dict.keys():\n",
    "            word_dict[tuple(dkey)].append(future)\n",
    "        else:\n",
    "            word_dict[tuple(dkey)] = [future]\n",
    "   \n",
    "    for i in range(int(n)):\n",
    "        first_word = []\n",
    "        index = random.randint(0, len(d) - 1)\n",
    "        key = (d[index], d[index + 1])\n",
    "        if '<bos>' not in key and '<eos>' not in key:\n",
    "            first_word = key        \n",
    "        sentence = list(first_word)\n",
    "        n_words = random.randint(1, 7)\n",
    "    \n",
    "        for i in range(n_words):             \n",
    "            w = np.random.choice(word_dict[key])\n",
    "            if w != '<bos>' and w != '<eos>':\n",
    "                sentence.append(w)\n",
    "            key = (key[1], w)\n",
    "        output = ' '.join(sentence)\n",
    "        print(' '.join(('<bos>', output,'<eos>')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter number of sentences: \n",
      "1\n",
      "('article', 'ii')\n",
      "('ii', 'of')\n",
      "('of', 'the')\n",
      "('the', '<unk>')\n",
      "('<unk>', 'countries')\n",
      "<bos> of article ii of the <unk> countries <eos>\n"
     ]
    }
   ],
   "source": [
    "print(\"Enter number of sentences: \")\n",
    "k = input()\n",
    "generate_text2(k, d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text2(n, dat): \n",
    "    \n",
    "    def create_dict(d):\n",
    "        for i in range(len(d) - 2):\n",
    "            yield (d[i], d[i + 1], d[i + 2])\n",
    "    chain_dict = create_dict(d)\n",
    "\n",
    "    word_dict = {}\n",
    "\n",
    "    for present, present2, future in chain_dict:\n",
    "        dkey = [present, present2]\n",
    "        if tuple(dkey) in word_dict.keys():\n",
    "            word_dict[tuple(dkey)].append(future)\n",
    "        else:\n",
    "            word_dict[tuple(dkey)] = [future]\n",
    "   \n",
    "    for i in range(int(n)):\n",
    "        first_word = []\n",
    "        index = random.randint(0, len(d) - 1)\n",
    "        key = (d[index], d[index + 1])\n",
    "        if '<bos>' not in key and '<eos>' not in key:\n",
    "            first_word = key        \n",
    "        sentence = list(first_word)\n",
    "        n_words = random.randint(1, 7)\n",
    "    \n",
    "        for i in range(n_words):             \n",
    "            w = np.random.choice(word_dict[key])\n",
    "            if w != '<bos>' and w != '<eos>':\n",
    "                sentence.append(w)\n",
    "            key = (key[1], w)\n",
    "            print(key)\n",
    "        output = ' '.join(sentence)\n",
    "        print(' '.join(('<bos>', output,'<eos>')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "PythonUnstructuredDataLanguageModels_Part2.ipynb",
   "provenance": [
    {
     "file_id": "16ChhU6LkUqXEouhuDM-OxURStQC7u-dt",
     "timestamp": 1571395606894
    }
   ],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
